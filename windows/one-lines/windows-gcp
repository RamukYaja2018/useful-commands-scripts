### command to copy a fully packed folder to gcp bucket (04-05-2025)
gsutil cp -r "H:\SQL_Backup\xp-asp1-db-pdn01_FULL\xp-aps1-db-p-1" gs://mssql_db_backups_asp1/xp-asp1-db-pdn01_FULL/xp-asp-db-pdn01/2025/05/04/

#

To copy files to a GCP bucket using gsutil, the service account you're using must have specific Cloud Storage IAM permissions. Here's what‚Äôs required:
‚úÖ Minimum Required Permission:
To upload (write) files to a bucket, the service account needs:

- storage.objects.create ‚Äî allows writing new objects
- storage.objects.get ‚Äî allows reading object metadata (optional but recommended for error-free ops)
- storage.objects.list ‚Äî to list existing objects (optional but helpful)

‚úÖ Recommended IAM Role:
You can grant a predefined role that includes the necessary permissions:

1. Storage Object Creator
Role ID: roles/storage.objectCreator
Grants: Ability to upload files, but not delete or overwrite
‚úÖ Use this for append-only scenarios or limited access

2. Storage Object Admin
Role ID: roles/storage.objectAdmin
Grants: Full control over objects in a bucket (create, delete, overwrite)
‚úÖ Use this for backup automation scripts and full access workflows

3. Storage Admin
Role ID: roles/storage.admin
Grants: Full access to both buckets and objects (create buckets, set permissions, etc.)
üîí Only use this if the script needs to manage buckets too.

#

üîê How to Assign the Role
Use this gcloud command (run as a project admin): example

gcloud projects add-iam-policy-binding <PROJECT_ID> \
  --member="serviceAccount:scripts@algo-app-hosting.iam.gserviceaccount.com" \
  --role="roles/storage.objectAdmin"


Replace:
<PROJECT_ID> with your actual project ID.
The service account email if different.
